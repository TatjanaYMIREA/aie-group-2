# HW06 – Report

## 1. Dataset
- **Выбранный датасет:** `S06-hw-dataset-02.csv`  
- **Размер:** (18000, 39)  
- **Целевая переменная:** `target`  
  - Классы: 0 – 73.7%, 1 – 26.3%  
- **Признаки:** 37 признаков без `id` и `target`  
  - Большинство числовые  
  - Есть категориальные-подобные признаки (целые значения с малой мощностью) и некоторые бинарные индикаторы  

---

## 2. Protocol
- **Разбиение:** train/test = 0.75 / 0.25  
  - `random_state=42`  
  - Использована стратификация (`stratify=y`) для сохранения пропорций классов  
- **Подбор гиперпараметров:**  
  - Кросс-валидация на train: StratifiedKFold с 5 фолдами  
  - Оптимизировали ROC-AUC для бинарной классификации  
- **Метрики:**  
  - `accuracy` – доля правильных ответов  
  - `F1` – баланс precision и recall для положительного класса  
  - `ROC-AUC` – качество ранжирования вероятностей, важно при несбалансированных классах  

---

## 3. Models
- **DummyClassifier** (strategy=`most_frequent`) – нижняя планка  
- **LogisticRegression** (Pipeline со StandardScaler) – baseline с линейной моделью  
- **DecisionTreeClassifier** – подбирали `max_depth`, `min_samples_leaf`, `ccp_alpha`  
- **RandomForestClassifier** – подбирали `max_depth`, `min_samples_leaf`, `max_features`  
- **HistGradientBoostingClassifier** – подбирали `learning_rate`, `max_depth`, `max_leaf_nodes`  
- **StackingClassifier** (опционально) – комбинировали LogReg, RF и HGB; метамодель – логистическая регрессия, CV внутри стекинга  

---

## 4. Results

| Model                     | Accuracy | F1      | ROC-AUC |
|----------------------------|---------|---------|---------|
| Stacking                   | 0.893   | 0.781   | 0.920   |
| RandomForest               | 0.868   | 0.686   | 0.919   |
| HistGradientBoosting       | 0.866   | 0.697   | 0.898   |
| DecisionTree               | 0.819   | 0.619   | 0.832   |
| LogisticRegression(scaled) | 0.816   | 0.572   | 0.801   |
| Dummy(most_frequent)       | 0.737   | 0.000   | 0.500   |

- **Победитель:** `Stacking`  
  - Наилучшие показатели по ROC-AUC и F1  
  - Сочетает сильные стороны разных моделей и снижает ошибки отдельных алгоритмов  

---

## 5. Analysis
- **Устойчивость:**  
  - Повторные прогоны с разными `random_state` показывают, что ансамбли (RF, HGB, Stacking) стабильнее одиночного дерева и логистической регрессии.  
- **Ошибки:**  
  - Confusion matrix для `Stacking` показывает высокую точность для класса 0 и хорошее обнаружение класса 1.  
  - Основные ошибки – редкие FN для класса 1, что ожидаемо при несбалансированном таргете.  
- **Интерпретация:**  
  - Permutation importance (top-15) выявила признаки, наиболее влияющие на прогноз.  
  - Наиболее значимые признаки – `f16`, `f01`, `f19`, `f23`, `f12` и др.  
  - Соответствует ожиданиям по распределению данных и силе сигналов в них.  

---

## 6. Conclusion
1. Деревья решений легко переобучаются, контроль сложности (`max_depth`, `min_samples_leaf`, `ccp_alpha`) критичен.  
2. Ансамбли деревьев (Random Forest, Gradient Boosting) значительно устойчивее и сильнее одного дерева.  
3. Stacking позволяет объединять разные подходы, улучшая итоговую точность и ранжирование.  
4. Честный ML-протокол (фиксированный train/test, CV на train, единые метрики, сохранение артефактов) обеспечивает воспроизводимость и корректное сравнение моделей.  
5. Использование permutation importance помогает понять вклад признаков и интерпретировать сложные ансамбли.  
