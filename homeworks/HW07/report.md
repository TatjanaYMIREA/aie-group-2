# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: ~12000 строк, числовые признаки
- Признаки: только числовые
- Пропуски: отсутствуют
- "Подлости" датасета: признаки находятся в разных шкалах, присутствуют шумовые признаки

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: ~12000 строк, числовые признаки
- Признаки: только числовые
- Пропуски: отсутствуют
- "Подлости" датасета: нелинейная структура кластеров, выбросы, шумовой признак

### 1.3 Dataset C

- Файл: `S07-hw-dataset-04.csv`
- Размер: ~12000 строк, смешанные признаки
- Признаки: числовые и категориальные
- Пропуски: есть пропуски в числовых признаках
- "Подлости" датасета: высокая размерность, категориальные признаки, пропуски, чувствительность к инициализации

---

## 2. Protocol

Для всех датасетов использовался единый честный unsupervised-протокол.

- **Препроцессинг**:
  - числовые признаки: `SimpleImputer(strategy="median")` + `StandardScaler`;
  - категориальные признаки (dataset-04): `OneHotEncoder(handle_unknown="ignore")`;
  - использовались `Pipeline` и `ColumnTransformer`.
- **Поиск гиперпараметров**:
  - KMeans: перебор `k` в диапазоне от 2 до 15, фиксированные `random_state` и `n_init`;
  - DBSCAN: перебор `eps` и `min_samples`;
  - AgglomerativeClustering: перебор `k` и нескольких вариантов `linkage`.
- **Критерий выбора лучшего решения**: максимум `silhouette_score` с учётом интерпретируемости и доли шума.
- **Метрики качества**:
  - `silhouette_score` (выше — лучше),
  - `davies_bouldin_score` (ниже — лучше),
  - `calinski_harabasz_score` (выше — лучше).
  Для DBSCAN метрики считались **только по non-noise точкам**, доля шума указывалась явно.
- **Визуализация**:
  - PCA(2D) для лучшего решения по каждому датасету;
  - графики подбора параметров (silhouette vs k / eps).

---

## 3. Models

Для каждого датасета сравнивались следующие модели:

- **KMeans**:
  - подбор `k`,
  - фиксированные `random_state` и `n_init`.
- **DBSCAN**:
  - подбор `eps` и `min_samples`,
  - анализ доли шума.
- **AgglomerativeClustering**:
  - подбор `k`,
  - сравнение разных `linkage` (ward, average).

Все модели применялись к одинаково предобработанным данным для каждого датасета.

---

## 4. Results

### 4.1 Dataset A

- Лучший метод и параметры: **KMeans, k = 2**
- Метрики:
  - silhouette = 0.522
  - Davies–Bouldin = 0.685
  - Calinski–Harabasz ≈ 11787
- DBSCAN: сопоставимое качество, но ≈49% объектов отнесены к шуму
- Вывод: структура данных близка к компактным сферическим кластерам, что делает KMeans и Agglomerative оптимальными

### 4.2 Dataset B

- Лучший метод и параметры: **AgglomerativeClustering, k = 2, linkage = average**
- Метрики:
  - silhouette = 0.42
  - Davies–Bouldin = 0.879
  - Calinski–Harabasz ≈ 396
- DBSCAN: высокая доля шума, ограниченная интерпретируемость
- Вывод: иерархический подход лучше справляется с нелинейной структурой данных

### 4.3 Dataset C

- Лучший метод и параметры: **AgglomerativeClustering, k = 5, linkage = ward**
- Метрики:
  - silhouette = 0.447
  - Davies–Bouldin ≈ 1.25
  - Calinski–Harabasz ≈ 90
- Вывод: метод устойчив к высокой размерности и работает лучше KMeans при наличии категориальных признаков и пропусков

---

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans хорошо работает на компактных и масштабированных данных, но чувствителен к форме кластеров и выбросам.
- DBSCAN эффективно выделяет плотные области, но часто отбрасывает значительную часть данных в шум.
- AgglomerativeClustering показал наилучший баланс качества и интерпретируемости на сложных датасетах.
- Масштабирование и корректный препроцессинг оказались критичны для всех методов.

### 5.2 Устойчивость (обязательно для одного датасета)

Для датасета ds4 была проведена проверка устойчивости KMeans при 5 разных `random_state`.  
Среднее значение ARI между разбиениями составило ≈0.9, минимальное — ≈0.89.  
Это указывает на **в целом устойчивую**, но не идеально стабильную кластеризацию, что объясняется сложной структурой и высокой размерностью данных.

### 5.3 Интерпретация кластеров

Кластеры интерпретировались через сравнение значений признаков и визуализацию в PCA-пространстве.  
Для простых датасетов кластеры соответствуют компактным группам наблюдений, тогда как для сложных данных отражают более абстрактные различия в комбинациях признаков.  
Визуализация помогла выявить перекрытия и влияние шума.

---

## 6. Conclusion

- Кластеризация требует аккуратного препроцессинга и подбора параметров.
- Одна метрика не даёт полной картины качества.
- KMeans эффективен на простых данных, но не универсален.
- DBSCAN полезен для поиска плотных структур, но чувствителен к параметрам.
- Иерархическая кластеризация показала себя наиболее гибким методом.
- PCA — полезный инструмент для интерпретации, но не критерий качества.
- Проверка устойчивости помогает выявить надёжность решений.